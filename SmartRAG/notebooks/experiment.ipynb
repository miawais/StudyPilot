{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "852da3f92380d8b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T13:18:49.409497Z",
     "start_time": "2025-06-26T13:18:16.791822Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\awais\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from groq import Groq\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b883ff9bb9f1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T13:19:19.760632Z",
     "start_time": "2025-06-26T13:19:15.272157Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "if INDEX_NAME not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "index = pc.Index(INDEX_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdc27931946cf035",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T13:19:34.650921Z",
     "start_time": "2025-06-26T13:19:23.019068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 136}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "with open(\"D:/Awais/Notebooks/cs_chapter.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Embedding and pushing\n",
    "batch = []\n",
    "for i, chunk in enumerate(data):\n",
    "    vector = model.encode(chunk[\"content\"]).tolist()\n",
    "    meta = chunk[\"metadata\"]\n",
    "    meta[\"text\"] = chunk[\"content\"]\n",
    "    batch.append((str(i), vector, meta))\n",
    "\n",
    "index.upsert(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaead0b71435b3f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T13:19:40.072995Z",
     "start_time": "2025-06-26T13:19:40.069461Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_query(query: str):\n",
    "    return query.strip().lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "511b781172111f1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T13:19:43.658615Z",
     "start_time": "2025-06-26T13:19:43.652302Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_metadata_from_query(query: str):\n",
    "    query = query.lower()\n",
    "    metadata = {}\n",
    "\n",
    "    # Detect chapters\n",
    "    if \"chapter 1\" in query or \"unit 1\" in query:\n",
    "        metadata[\"chapter\"] = \"Unit 1: Problem Solving\"\n",
    "\n",
    "    # Detect topic numbers like 1.2, 1.3, etc.\n",
    "    topic_match = re.search(r\"\\b1\\.\\d+\\b\", query)\n",
    "    if topic_match:\n",
    "        topic_num = topic_match.group()\n",
    "        metadata[\"topic\"] = f\"{topic_num} Flowcharts\" if \"flowchart\" in query else f\"{topic_num}\"\n",
    "\n",
    "    # Detect subtopics (customize for more)\n",
    "    if \"importance\" in query:\n",
    "        metadata[\"subtopic\"] = \"1.2.2 Importance of Flowcharts in Problem Solving\"\n",
    "    elif \"requirements\" in query:\n",
    "        metadata[\"subtopic\"] = \"1.2.3 Determining Requirements for a Flowchart\"\n",
    "    elif \"symbols\" in query:\n",
    "        metadata[\"subtopic\"] = \"1.2.4 Using Flowchart Symbols\"\n",
    "\n",
    "    # Detect types of content\n",
    "    if \"activity\" in query:\n",
    "        metadata[\"type\"] = \"activity\"\n",
    "    elif \"mcq\" in query or \"multiple choice\" in query:\n",
    "        metadata[\"type\"] = \"mcq\"\n",
    "    elif \"short question\" in query:\n",
    "        metadata[\"type\"] = \"short_question\"\n",
    "    elif \"long question\" in query:\n",
    "        metadata[\"type\"] = \"long_question\"\n",
    "\n",
    "    return metadata\n",
    "\n",
    "\n",
    "def retrieve_relevant_chunks(query, top_k=30, filter_meta=None):\n",
    "    query_vector = model.encode(query).tolist()\n",
    "\n",
    "    # ðŸ” Auto-extract metadata from query if no external filter provided\n",
    "    if filter_meta is None:\n",
    "        filter_meta = extract_metadata_from_query(query)\n",
    "\n",
    "    print(\"ðŸ§  Metadata Filter Applied:\", filter_meta)  # DEBUG\n",
    "\n",
    "    response = index.query(\n",
    "        vector=query_vector,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        include_values=False,\n",
    "        filter=filter_meta\n",
    "    )\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            \"content\": match[\"metadata\"].get(\"text\", \"\"),\n",
    "            \"metadata\": match.get(\"metadata\", {})\n",
    "        }\n",
    "        for match in response.get(\"matches\", [])\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcb8ea8e181865b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T13:19:45.641024Z",
     "start_time": "2025-06-26T13:19:45.636812Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_prompt(context_chunks, user_query):\n",
    "    # Create a readable structured context\n",
    "    context = \"\\n---\\n\".join([\n",
    "        f\"[{chunk['metadata'].get('chapter', '')} > {chunk['metadata'].get('topic', '')} > {chunk['metadata'].get('subtopic', '')} | {chunk['metadata'].get('type', '')}]\\n{chunk['content']}\"\n",
    "        for chunk in context_chunks\n",
    "        if chunk.get(\"content\")\n",
    "    ])\n",
    "\n",
    "    prompt = f\"\"\"You are an educational AI assistant for 9th grade Computer Science students in Pakistan. \n",
    "Use only the context provided below to answer the user's question. Be specific, use chapter/topic/subtopic hierarchy when available, and **do not guess**. \n",
    "If the answer isn't in the context, say \"I don't know based on the provided material.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "User Question:\n",
    "{user_query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcfab1ed34dd54e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T13:19:48.198371Z",
     "start_time": "2025-06-26T13:19:47.573749Z"
    }
   },
   "outputs": [],
   "source": [
    "groq_client = Groq(api_key=GROQ_API_KEY)\n",
    "\n",
    "def run_llm(prompt, model_name=\"llama3-8b-8192\"):\n",
    "    response = groq_client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI tutor for 9th grade computer science.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=300\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "777b542e0eedca60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T13:19:54.601330Z",
     "start_time": "2025-06-26T13:19:54.597182Z"
    }
   },
   "outputs": [],
   "source": [
    "def chat():\n",
    "    print(\"ðŸ’¬ AI Tutor: Hi! Ask me anything from your Computer Science book. Type 'exit' to stop.\")\n",
    "    while True:\n",
    "        user_query = input(\"ðŸ‘¦ You: \")\n",
    "        if user_query.lower() in ['exit', 'quit']:\n",
    "            print(\"ðŸ‘‹ AI Tutor: Goodbye! Stay curious.\")\n",
    "            break\n",
    "\n",
    "        processed_query = preprocess_query(user_query)\n",
    "        relevant_chunks = retrieve_relevant_chunks(processed_query)\n",
    "        prompt = build_prompt(relevant_chunks, processed_query)\n",
    "        answer = run_llm(prompt)\n",
    "        print(\"ðŸ¤– AI Tutor:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ab124db5be746b27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T15:02:06.980364Z",
     "start_time": "2025-06-25T15:02:06.976026Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a9cd1de15a760f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T13:21:41.236603Z",
     "start_time": "2025-06-26T13:21:09.898269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¬ AI Tutor: Hi! Ask me anything from your Computer Science book. Type 'exit' to stop.\n",
      "ðŸ§  Metadata Filter Applied: {'type': 'mcq'}\n",
      "ðŸ¤– AI Tutor: Based on the provided context, there are 7 MCQs in the exercise of Chapter 2: Binary Systems.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m, in \u001b[0;36mchat\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ’¬ AI Tutor: Hi! Ask me anything from your Computer Science book. Type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to stop.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 4\u001b[0m     user_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mðŸ‘¦ You: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_query\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ‘‹ AI Tutor: Goodbye! Stay curious.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "chat()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
